{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never have multiple notebooks and kernels reading the video stream from a camera at the same time as they might start conflicting with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "print(F'cv2 version = {cv2.__version__}')\n",
    "\n",
    "# To find the id of the desired camera, execute\n",
    "# $ v4l2-ctl --list-devices\n",
    "# The output will contain the name of the camera and its matching device(s), in form /dev/videoN\n",
    "# This N is the device ID\n",
    "deviceId = 0\n",
    "\n",
    "# cv2a.videoio_registry.getBackends() returns list of all available backends.\n",
    "availableBackends = [cv2.videoio_registry.getBackendName(b) for b in cv2.videoio_registry.getBackends()]\n",
    "print(availableBackends)\n",
    "\n",
    "# Returns list of available backends which works via cv::VideoCapture(int index)\n",
    "availableCameraBackends = [cv2.videoio_registry.getBackendName(b) for b in cv2.videoio_registry.getCameraBackends()]\n",
    "print(availableBackends)\n",
    "\n",
    "# output: ['FFMPEG', 'GSTREAMER', 'CV_IMAGES', 'CV_MJPEG']\n",
    "\n",
    "# capture\n",
    "# cap = cv2.VideoCapture(deviceId)\n",
    "#videoCaptureApi = cv2.CAP_ANY        # autodetect default API\n",
    "#videoCaptureApi = cv2.CAP_FFMPEG\n",
    "#videoCaptureApi = cv2.CAP_GSTREAMER \n",
    "#videoCaptureApi = cv2.CAP_V4L2 \n",
    "#videoCaptureApi = cv2.CAP_IMAGES\n",
    "videoCaptureApi = cv2.CAP_OPENCV_MJPEG\n",
    "cap = cv2.VideoCapture(\"/dev/video2\", videoCaptureApi)\n",
    "\n",
    "# cap is of type cv2.VideoCapture\n",
    "print(f'type(cap) = {type(cap)}')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"ERROR! Unable to open camera\")\n",
    "\n",
    "try:\n",
    "    # width and height of the capture is required for manipulating the image\n",
    "    # # get() returns float e.g. 1080.0 and we can cast it to int via `int()`\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    heigth = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    while True:\n",
    "        # A capture is a series of images.\n",
    "        # Each camera has a property called capture frame rate.\n",
    "        # It denotes how frequently camera captures the frame. \n",
    "        # Its measurement unit is Frames Per Second FPS (e.g. 60 fps).\n",
    "        # An image buffer is updated each time a new capture occurs.\n",
    "        # A frame is a single image and we can read it from buffer. \n",
    "        # Once we get the frame, we can process it just like we processed\n",
    "        # images loaded from the disk.\n",
    "        #\n",
    "        # tuple unpacking\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # convert a frame into grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame', gray)\n",
    "\n",
    "        # press 'q' for exit:\n",
    "        #    wait 1 millisecond and check if 'q' was pressed\n",
    "        #    ord() returns the integer that represents the character\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# FFMPEG_BIN = '/usr/bin/ffmpeg'\n",
    "# To get this path execute:\n",
    "#    $ which ffmpeg\n",
    "FFMPEG_BIN = '/home/bojan/anaconda3/envs/python-cvcourse/bin/ffmpeg'\n",
    "\n",
    "# to find allowed formats \n",
    "#    $ ffmpeg -f v4l2 -list_formats all -i /dev/video3\n",
    "#    ...\n",
    "#    [video4linux2,v4l2 @ 0x5608ac90af40] Raw: yuyv422: YUYV 4:2:2: 640x480 1280x720 960x544 800x448 640x360 424x240 352x288 320x240 800x600 176x144 160x120 1280x800\n",
    "#    ...\n",
    "\n",
    "# /home/bojan/anaconda3/envs/python-cvcourse/bin/ffmpeg -i /dev/video2 -video_size 640x480 -r 1 -pix_fmt bgr24 -vcodec rawvideo -an -sn -f v4l2\n",
    "def run_ffmpeg():\n",
    "    ffmpg_cmd = [\n",
    "        FFMPEG_BIN,\n",
    "        '-i', '/dev/video3',\n",
    "        # '-framerate', '25',\n",
    "        '-video_size', '640x480',\n",
    "        # '-r', '1',                # framerate (fps, default is 25)\n",
    "        '-pix_fmt', 'bgr24',        # opencv requires bgr24 pixel format. 'yuyv422'\n",
    "        '-vcodec', 'rawvideo',\n",
    "        '-an','-sn',                # disable audio processing\n",
    "        # '-f', 'v4l2',\n",
    "        '-f', 'image2pipe',\n",
    "        '-',                        # output to go to stdout\n",
    "    ]\n",
    "    return subprocess.Popen(ffmpg_cmd, stdout = subprocess.PIPE, bufsize=10**8)\n",
    "\n",
    "def run_cv_window(process):\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        raw_image = process.stdout.read(640*480*3)\n",
    "        # print(type(raw_image))\n",
    "        # print(raw_image) # only for debugging but it might make browser unresponsive due to large amount of data being appended to the display in this tab\n",
    "        if raw_image == b'':\n",
    "            raise RuntimeError(\"Empty pipe\")\n",
    "        \n",
    "        # transform the byte read into a numpy array\n",
    "        frame =  np.frombuffer(raw_image, dtype='uint8')\n",
    "        frame = frame.reshape((480,640,3))          # height, width, colours\n",
    "        if frame is not None:\n",
    "            # cv2.imshow('Video', frame) # uncomment to show the original image\n",
    "            \n",
    "            # example how to edit captured frame and then display it\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow('frame', gray)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        process.stdout.flush()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    process.terminate()\n",
    "    print(process.poll())\n",
    "\n",
    "\n",
    "def run():\n",
    "    ffmpeg_process = run_ffmpeg()\n",
    "    run_cv_window(ffmpeg_process)\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
