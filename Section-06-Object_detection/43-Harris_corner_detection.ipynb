{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corner Detection (Part 1) - Harris Corner Detection\n",
    "\n",
    "[Corner detection (Wikipedia)](https://en.wikipedia.org/wiki/Corner_detection)\n",
    "\n",
    "A corner is:\n",
    "* a point whose local neighbourhood stands in two dominant and different edge directions.\n",
    "* a junction of two edges where edge is a sudden change in image brightness\n",
    "\n",
    "Why is corner detecton important?\n",
    "* _Although corners are only a small percentage of the image, they contain the most important features in restoring image information, and they can be used to minimize the amount of processed data for motion tracking, image stitching, building 2D mosaics, stereo vision, image representation and other related computer vision areas._ (Wikipedia)\n",
    "\n",
    "Two most popular corner detection models:\n",
    "* Harris\n",
    "* Shi-Tomasi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harris Corner Detection\n",
    "\n",
    "[Harris Corner Detector (Wikipedia)](https://en.wikipedia.org/wiki/Harris_Corner_Detector)\n",
    "\n",
    "* Chris Harris, Mike Stephens (1988)\n",
    "* corners can be detected by looking a significant change in all directions\n",
    "* sliding window going over corner will detect significant changes \n",
    "* here's the formula - a sum of squared difference (SSD) in intensity between neighbouring pixels:\n",
    "    * I = Intensity\n",
    "    * W = Window\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x, y) = \\sum_{(x_k, y_k) \\in W}(I(x_k, y_k) - I(x_k + \\Delta{x}, y_k + \\Delta{y}))^2 \n",
    "\\end{equation*}\n",
    "\n",
    "* scoring criteria:\n",
    "\n",
    "\\begin{equation*}\n",
    "R = \\lambda_1\\lambda_2 - k(\\lambda_1 + \\lambda_2)\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_chess = cv2.imread('../data/flat_chessboard.png')\n",
    "flat_chess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flat_chess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_chess = cv2.cvtColor(flat_chess, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(flat_chess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_flat_chess = cv2.cvtColor(flat_chess, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray_flat_chess, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_chess = cv2.imread('../data/real_chessboard.jpg')\n",
    "real_chess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_chess = cv2.cvtColor(real_chess, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(real_chess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_real_chess = cv2.cvtColor(real_chess, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_real_chess, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_flat_chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to conver integers to floating points which is required for cv2.cornerHarris()\n",
    "gray = np.float32(gray_flat_chess)\n",
    "gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cv2.cornerHarris()](https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#gac1fc3598018010880e370e2f709b4345)\n",
    "\n",
    "Harris corner detector. It computes the response map. Corners in the image can be found as the local maxima of this response map.\n",
    "\n",
    "* `src` - Input single-channel 8-bit or floating-point image.\n",
    "* `dst` - Image to store the Harris detector responses. It has the type CV_32FC1 and the same size as src .\n",
    "* `blockSize` - Neighborhood size (see the details on cornerEigenValsAndVecs ).\n",
    "* `ksize` - Aperture parameter for the Sobel operator. (`cv2.cornerHarris()` uses Sobel operator)\n",
    "* `k` - Harris detector free parameter. See the formula above. Usual default value is `0.04`.\n",
    "* `borderType` - Pixel extrapolation method. See BorderTypes. BORDER_WRAP is not supported.\n",
    "\n",
    "[Difference between OpenCV type CV_32F and CV_32FC1] (https://stackoverflow.com/questions/37530368/difference-between-opencv-type-cv-32f-and-cv-32fc1)\n",
    "\n",
    "From [why is CV_32FC1 not normalized to 0-1?](https://answers.opencv.org/question/179914/why-is-cv_32fc1-not-normalized-to-0-1/):\n",
    "_The CV_32FC1 Mat type has a range from 1.17549e-38 to 3.40282e+38 (I got these values from std::numeric_limits<float>). If the value is less than 0, it is shown as black. If the value is greater than 1, it is shown as white. This all comes in handy when you want to flood fill all of the regions in your image with a unique colour, and you have more than 65536 regions to contend with._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.cornerHarris(src=gray, blockSize=2, ksize=3, k=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = cv2.dilate(dst, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_chess[dst > 0.01 * dst.max()] = [255, 0, 0] # red in RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flat_chess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_real_chess_float = np.float32(gray_real_chess)\n",
    "dst_real_chess = cv2.cornerHarris(src=gray_real_chess_float, blockSize=2, ksize=3, k=0.04)\n",
    "dst_real_chess = cv2.dilate(dst_real_chess, None)\n",
    "real_chess[dst_real_chess > 0.01 * dst_real_chess.max()] = [255, 0, 0] # red in RGB\n",
    "plt.imshow(real_chess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
