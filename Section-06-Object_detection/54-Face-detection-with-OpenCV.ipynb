{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images as grayscale (pass cv2.IMREAD_GRAYSCALE or 0)\n",
    "img_woman = cv2.imread('../data/Nadia_Murad.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img_man = cv2.imread('../data/Denis_Mukwege.jpg', 0)\n",
    "img_people = cv2.imread('../data/solvay_conference.jpg', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns None if loading image failed (for e.g. wrong path)\n",
    "print(img_woman)\n",
    "\n",
    "plt.imshow(img_woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_woman, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_man, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_people, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a classifier and pass in the XML classifier.\n",
    "# OpenCV comes with pretrained cascade files.\n",
    "\n",
    "# This is a list of ~6000 features that are going to be passed through the image to see if it fits all the features; \n",
    "# if it does, that means that the image contains a face.\n",
    "face_classifier = cv2.CascadeClassifier('../data/haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img):\n",
    "    img_out = img.copy()\n",
    "    rectangles = face_classifier.detectMultiScale(img_out)\n",
    "    \n",
    "    # (x, y) is top left corner\n",
    "    for (x, y, w, h) in rectangles:\n",
    "        # (255, 255, 255) is white color of the rectangle; 10 is thickness\n",
    "        cv2.rectangle(img_out, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_faces(img_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_faces(img_woman)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_faces(img_people)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see above, it detects a gargoil as face and some faces are detected twice.\n",
    "# To fix this, we'll use detectMultiScale's two additional parameters:\n",
    "# - Scale factor: specifies how much is the image size reduced at each image scale\n",
    "# - Minimum neighbours: how many neighbours each candidate rectangle should have to retain it. \n",
    "#                       Multiple rectangles detect the face, if they are near the same area or have a minimum number of neighbours that's where the face is.\n",
    "\n",
    "def detect_faces_improved(img):\n",
    "    img_out = img.copy()\n",
    "    rectangles = face_classifier.detectMultiScale(img_out, scaleFactor = 1.2, minNeighbors = 5)\n",
    "    \n",
    "    # (x, y) is top left corner\n",
    "    for (x, y, w, h) in rectangles:\n",
    "        # (255, 255, 255) is white color of the rectangle; 10 is thickness\n",
    "        cv2.rectangle(img_out, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_faces_improved(img_people)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see in the outuput image, the face of the person who does not look at camera is not detected.\n",
    "# This is because we're using Cascade classifier optimized/trained for detecting front-facing faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_classifier = cv2.CascadeClassifier('../data/haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_eyes_improved(img):\n",
    "    img_out = img.copy()\n",
    "    rectangles = eye_classifier.detectMultiScale(img_out, scaleFactor = 1.2, minNeighbors = 5)\n",
    "    \n",
    "    # (x, y) is top left corner\n",
    "    for (x, y, w, h) in rectangles:\n",
    "        # (255, 255, 255) is white color of the rectangle; 10 is thickness\n",
    "        cv2.rectangle(img_out, (x, y), (x + w, y + h), (255, 255, 255), 10)\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_eyes_improved(img_woman)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect_eyes_improved(img_man)\n",
    "plt.imshow(result, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see from the output above, classifier didn't detect eyes on the man's face. \n",
    "# This is because within his eyes there is no enough contrast between dark eye centre (pupil) and white eye ball (sclera)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing faces/eyes on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read(0)\n",
    "    frame = detect_faces_improved(frame)\n",
    "    cv2.imshow('Video face detection', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
