{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Matching\n",
    "\n",
    "\n",
    "[Template matching (Wikipedia)](https://en.wikipedia.org/wiki/Template_matching)\n",
    "\n",
    "[Template Matching (OpenCV doc)](https://docs.opencv.org/master/d4/dc6/tutorial_py_template_matching.html)\n",
    "\n",
    "[Template Matching](https://docs.opencv.org/3.4/de/da9/tutorial_template_matching.html)\n",
    "\n",
    "\n",
    "* the simplest form of object detection\n",
    "* scans a larger image for a provided template by sliding the template target image across the larger image\n",
    "* a choice on comparison method used; these methods are all some sort of correlation-based metric: [TemplateMatchModes](https://docs.opencv.org/master/df/dfb/group__imgproc__object.html#gga3a7850640f1fe1f58fe91a2d7583695dac5babb7dfda59544e3e31ea928f8cb16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a large image, inside which we'll be looking for a pattern\n",
    "full = cv2.imread('../data/sammy.jpg')\n",
    "full = cv2.cvtColor(full, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a template image, the one which we'll be searching within the large image\n",
    "face = cv2.imread('../data/sammy_face.jpg')\n",
    "face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cv2.matchTemplate()](https://docs.opencv.org/3.4/df/dfb/group__imgproc__object.html#ga586ebfb0a7fb604b35a23d85391329be) compares a template against overlapped image regions and creates a grayscale heatmap. \n",
    "\n",
    "_After the function finishes the comparison, the best matches can be found as global minimums (when TM_SQDIFF was used) or maximums (when TM_CCORR or TM_CCOEFF was used) using the minMaxLoc function._\n",
    "\n",
    "_In case of a color image, template summation in the numerator and each sum in the denominator is done over all of the channels and separate mean values are used for each channel. That is, the function can take a color template and a color image. The result will still be a single-channel image, which is easier to analyze._\n",
    "\n",
    "[python - Maxvalue in cv2.minMaxLoc()? - Stack Overflow](https://stackoverflow.com/questions/45047808/maxvalue-in-cv2-minmaxloc):\n",
    "_cv2.matchTemplate returns a correlation map, essentially a grayscale image, where each pixel denotes how much does the neighborhood of that pixel match with the template._\n",
    "_cv2.minMaxLoc() function returns the max and min intensity values in a Mat or an array along with the location of these intensities._\n",
    "\n",
    "For non-SQDIFF methods brighter colours (max values) appear at the location where match is found. \n",
    "\n",
    "For SQDIFF methods darker colours (min values) appear at the location where match is found.\n",
    "\n",
    "[computer vision - What does the TM_CCORR and TM_CCOEFF in opencv mean? - Stack Overflow](https://stackoverflow.com/questions/55469431/what-does-the-tm-ccorr-and-tm-ccoeff-in-opencv-mean)\n",
    "\n",
    "From \"Learning OpenCV 3: Computer Vision in C++ with the OpenCV Library\" By Adrian Kaehler, Gary Bradski:\n",
    "\n",
    "**TM_CCORR** = Cross correlation; a direct (\"simplest\") correlation between template and image: result pixel is the sum of the dot product of between the template pixel and and image pixel for each pixel in the template. (The *dot product* is the sum of the products of the corresponding entries of the two sequences of numbers\n",
    "\n",
    "**TM_CCOEFF** = Correlation coefficient; takes into account the dimensions of the template and image along with the sum of the pixel intensities.\n",
    "\n",
    "**TM_SQDIFF** = Square Difference; uses the squared distance between template and image pixel intensities.\n",
    "\n",
    "_The square-difference methods show best matches with a minimum, whereas the correlation and correlation-coefficient methods show best matches at\n",
    "maximum points._\n",
    "\n",
    "_We obtain more accurate matches (at the cost of more computations) as we move from simpler measures (square difference) to more sophisticated ones (correlation coefficient). Itâ€™s best to do some test trials of all these settings and then choose the one that best trades off accuracy for speed in your application._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv2.matchTemplate(full, face, eval('cv2.TM_CCOEFF'))\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are all TemplateMatchModes listed as strings in an array\n",
    "methods = [\n",
    "    'cv2.TM_CCOEFF',\n",
    "    'cv2.TM_CCOEFF_NORMED',\n",
    "    'cv2.TM_CCORR',\n",
    "    'cv2.TM_CCORR_NORMED',\n",
    "    'cv2.TM_SQDIFF', \n",
    "    'cv2.TM_SQDIFF_NORMED',\n",
    "]\n",
    "\n",
    "for m in methods:\n",
    "    full_copy = full.copy()\n",
    "    method = eval(m)\n",
    "    res = cv2.matchTemplate(full_copy, face, method)\n",
    "    min_value, max_value, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    \n",
    "    print(f'min_value = {min_value}, max_value = {max_value}')\n",
    "    \n",
    "    # min_loc (or max_loc) are locations of the top left corner of the pattern found in the full image\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    \n",
    "    height, width, channels = face.shape    \n",
    "    bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "    \n",
    "    cv2.rectangle(full_copy, top_left, bottom_right, (255, 0, 0), 10)\n",
    "    \n",
    "    # draw one raw with two columns,take 1st (left) image\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(res, cmap='gray')\n",
    "    plt.title('heatmap of template matching')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(full_copy)\n",
    "    plt.title('detection of template')\n",
    "    plt.suptitle(m)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
