{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed Algorithm (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, cmap='gray'):\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../data/pennies.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply blur; as image is large 3000x4000px we need to apply a strong blur (use large kernel)\n",
    "img_blur = cv2.medianBlur(img, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to grayscale\n",
    "img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a threshold\n",
    "ret, img_thresh = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still see some features on coins (they are these black areas inside white coins).\n",
    "To prevent appearance of these isolated features we'll apply [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method) of thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, img_thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal (optional in this simple use case)\n",
    "kernel = np.ones((3, 3), np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_open = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel, iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab sure background\n",
    "sure_bg = cv2.dilate(img_open, kernel, iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sure_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a fundamental problem here: all coins are still connected into a single blob (a single foreground object).\n",
    "\n",
    "We want to set \"seeds\" that we are sure they are in the foreground. In our example, we want 6 seeds, one in the center of each coin. \n",
    "\n",
    "So how can we be sure that seeds are placed in the foregrond objects? We need to use a [distance transform](https://en.wikipedia.org/wiki/Distance_transform). If we're given a binary image (0s and 255s), distance transformation transforms the image in such way that the pixels more distant from the black (zeros) get more brighter.  \n",
    "\n",
    "[Distance Transform](https://homepages.inf.ed.ac.uk/rbf/HIPR2/distance.htm)\n",
    "\n",
    "Applied to our image, we can expect that the brightest pixels will be at coin centers and the darkest around coin edges (closest to the black pixels).\n",
    "\n",
    "If we then apply thresholding again on that, we'll get 6 points that we are sure that are within coins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance transform\n",
    "img_dist_trans = cv2.distanceTransform(img_open, cv2.DIST_L2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_dist_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply another thresholding; the result is sure foreground\n",
    "ret, img_thresh_2 = cv2.threshold(img_dist_trans, 0.7 * img_dist_trans.max(), 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img_thresh_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are absolutely sure these 6 points are in the foreground.\n",
    "\n",
    "All white (foreground) pixels that are present in `img_open` but not in `img_thresh_2` are \"unknown regions\" (regions that we are not sure if they belong to foreground or background) that watershed algorithm has to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sure foreground\n",
    "sure_fg = np.uint8(img_thresh_2)\n",
    "unknown = cv2.subtract(sure_bg, sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the regions that we are not sure if they belong to foreground or background. We're going to make label markers at those 6 points in `sure_fg` and use them as seeds that watershed algorithm uses to find foreground segments.\n",
    "\n",
    "[Connected-component labeling](https://en.wikipedia.org/wiki/Connected-component_labeling)\n",
    "* subsets of connected components are uniquely labeled based on a given heuristic. \n",
    "* used to detect connected regions in binary digital images\n",
    "* Connected-component labeling is not to be confused with segmentation.\n",
    "\n",
    "[cv::connectedComponents()](https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#gaedef8c7340499ca391d459122e51bef5)\n",
    "\n",
    "```\n",
    "retval, labels = cv.connectedComponents(image[, labels[, connectivity[, ltype]]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 steps to create markers\n",
    "\n",
    "ret, labels = cv2.connectedComponents(sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how many unique regions have been detected\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we see spatial distribution of these values, we can see that label with value 0 is assigned to background - first and last values belong to first and last rows of pixels:\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to add 1 so sure background is not 0 but 1\n",
    "labels = labels + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check that background indeed has label 1 now:\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We did this as we want to mark the region of unknown with zeros (so only unknown region is black)\n",
    "labels[unknown==255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have clearly labeled a gray sure background, a black sure unknown region and 6 sure markers (which will act as seeds for watershed algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply watershed algorithm to markers\n",
    "markers = cv2.watershed(img, labels)\n",
    "display(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(markers.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    if hierarchy[0][i][3] == -1:  # is it external contour?\n",
    "        cv2.drawContours(img, contours, i, (255, 0, 0), 10) # red contours, thickness = 10\n",
    "        \n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So watershed algorithm works like this: \n",
    "* imagine having interconnected water pools but each pool is at different height\n",
    "* you have buckets of various colours and number of buckets matches number of pools\n",
    "* you then dip a brush in one bucket and then dip it in the centre of the firt pool - the colour will fill entire pool\n",
    "* repeat this for all other buckets and pools - each pool will be colour with different colour \n",
    "* once you have these regions painted in different colours, you can draw countours around the each of them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
