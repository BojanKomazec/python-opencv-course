{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending and pasting images - Part 2 - Masks\n",
    "\n",
    "When we blended images of the same size in Section 23 we can see that the background color of smaller image gets blended as well and affects the matching pixels of the other image. What we want to do now is to blend only the main/prominent object from one (smaller) image, without its background, into another (bigger) image. To achieve this, we need to perform several steps:\n",
    "* extract ROI (region of interest) from larger image; it matches the dimensions of the smaller image\n",
    "* create a grayscale (2D) mask which matches the object on the smaller image\n",
    "* [this seems not necessary] convert grayscale mask into colour (3D) mask which matches (all 3) dimensions of the smaller image\n",
    "* apply the 3D mask on the smaller image in order to extract only the object (foreground)\n",
    "* blend ROI and foreground to get final version of ROI\n",
    "* replace ROI with final ROI\n",
    "\n",
    "The process above will be shown on the example of adding a watermark on an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending together images of different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('../data/dog_backpack.png') # OpenCV reads images as BGR\n",
    "print(type(img1))\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.imread('../data/watermark_no_copy.png')\n",
    "print(type(img2))\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.resize(img2, (600, 600)) # this is a small image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a ROI (Region Of Interest) on the larger image. This is an area of larger image where we want to blend second (smaller) image into. Let's show the larger image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say this time we want to blend smaller image (`img2`) in the bottom right corner of the large image (`img1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'img1.shape = {img1.shape}')\n",
    "print(f'img2.shape = {img2.shape}')\n",
    "rows, columns, channels = img2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offset coordinates are top left corner of the ROI\n",
    "x_offset = img1.shape[1] - img2.shape[1]\n",
    "y_offset = img1.shape[0] - img2.shape[0]\n",
    "roi = img1[y_offset:img1.shape[0], x_offset:img1.shape[1]]\n",
    "plt.imshow(roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a grayscale (2D) mask\n",
    "\n",
    "This mask has to have the same `width x height` as the (smaller) image and we want to have pixels of the main object to be white (`np.uint8` value `255` in grayscale) and the rest (background) to be black (`0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's turn smaller image into greyscale\n",
    "img2_grey = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "print(f'img2_grey = {img2_grey}')\n",
    "\n",
    "# note that this color conversion actually removes 1 dimension (color channels) from the original image\n",
    "print(f'img2.shape = {img2.shape}')\n",
    "print(f'img2_grey.shape = {img2_grey.shape}')\n",
    "plt.imshow(img2_grey) # by default imshow() uses Viridis color mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's show the image in greyscale color mapping (which makes more sense now our image is grayscale)\n",
    "plt.imshow(img2grey, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a mask, we want to inverse this image actually as we want white to follow the shape of the object on the image that we want to be shown and black to be the background.\n",
    "\n",
    "Read [Arithmetic Operations on Images](https://docs.opencv.org/master/d0/d86/tutorial_py_image_arithmetics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.bitwise_not(img2grey)\n",
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mask` is a grayscale image so has only 2 dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a colour (3D) mask [This seems unnecessary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mask has to have the same `width x height x depth` as the (smaller) image and we want to have pixels of the main object to be white (`np.uint8` value `255` in grayscale) and the rest (background) to be black (`0`) in each (RGB) channel.\n",
    "\n",
    "To blend `img2` image into `img1` we need to apply this mask to each RGB channel of `img2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "white_background = np.ones(img2.shape) * 255\n",
    "print(f'white_background.shape = {white_background.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to fill an arbitrary (N-dimensional) array with an arbitrary values we can use [numpy.full(shape, fill_value, dtype)](https://numpy.org/doc/stable/reference/generated/numpy.full.html) function which returns a new array of given `shape` and `type`, filled with `fill_value`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'type(mask[0, 0]) = {type(mask[0, 0])}')\n",
    "# data type has to match data type of mask elements\n",
    "white_background = np.full(img2.shape, 255, dtype=np.uint8)\n",
    "print(f'white_background.shape = {white_background.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to combine 600x600 mask and 600x600 white background into 600x600x3 matrix. \n",
    "We can use [dst = cv2.bitwise_or(rc1, src2\\[, dst\\[, mask\\]\\])](https://docs.opencv.org/master/d2/de8/group__core__array.html#gab85523db362a4e26ff0c703793a719b4) which has the following arguments:\n",
    "* `src1` - first input array or a scalar.\n",
    "* `src2` - second input array or a scalar.\n",
    "* `dst` - output array that has the same size and type as the input arrays (this is optional )\n",
    "* `mask` - optional operation mask, 8-bit single channel array, that specifies elements of the output array to be changed.\n",
    "In case of multi-channel arrays, each channel is processed independently. \n",
    "\n",
    "This last sentence is very important as this means that if we have 3-D array, bitwise operation is applied layer by layer (on 2-D matrices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background\n",
    "mask3d = cv2.bitwise_or(white_background, white_background, mask=mask)\n",
    "print(f'mask3d.shape = {mask3d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the colour (3D) foreground\n",
    "\n",
    "Here we want to get the main object displayed as it is, in the original colours and everything we don't want to show (background) to be in black. We can get this if we apply mask to all 3 channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground = cv2.bitwise_or(img2, img2, mask=mask)\n",
    "print(f'foreground.shape = {foreground.shape}')\n",
    "plt.imshow(foreground)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the final version of ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_roi = cv2.bitwise_or(roi, foreground)\n",
    "plt.imshow(final_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the original version of ROI with the final one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_img = img1\n",
    "small_img = final_roi\n",
    "\n",
    "large_img[y_offset : img1.shape[0], x_offset : img1.shape[1]] = small_img\n",
    "plt.imshow(large_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
